# This file was generated based on ".graphqlconfig". Do not edit manually.

schema {
    query: query_root
    mutation: mutation_root
    subscription: subscription_root
}

type PageInfo {
    endCursor: String!
    hasNextPage: Boolean!
    hasPreviousPage: Boolean!
    startCursor: String!
}

"mutation root"
type mutation_root {
    "delete data from the table: \"organization\""
    delete_organization(
        "filter the rows which have to be deleted"
        where: organization_bool_exp!
    ): organization_mutation_response
    "delete single row from the table: \"organization\""
    delete_organization_by_pk(id: Int!): organization
    "delete data from the table: \"organization_invite_user\""
    delete_organization_invite_user(
        "filter the rows which have to be deleted"
        where: organization_invite_user_bool_exp!
    ): organization_invite_user_mutation_response
    "delete single row from the table: \"organization_invite_user\""
    delete_organization_invite_user_by_pk(id: Int!): organization_invite_user
    "delete data from the table: \"project\""
    delete_project(
        "filter the rows which have to be deleted"
        where: project_bool_exp!
    ): project_mutation_response
    "delete single row from the table: \"project\""
    delete_project_by_pk(id: Int!): project
    "delete data from the table: \"run\""
    delete_run(
        "filter the rows which have to be deleted"
        where: run_bool_exp!
    ): run_mutation_response
    "delete single row from the table: \"run\""
    delete_run_by_pk(id: bigint!): run
    "delete data from the table: \"run_path\""
    delete_run_path(
        "filter the rows which have to be deleted"
        where: run_path_bool_exp!
    ): run_path_mutation_response
    "delete single row from the table: \"run_path\""
    delete_run_path_by_pk(id: bigint!): run_path
    "delete data from the table: \"user\""
    delete_user(
        "filter the rows which have to be deleted"
        where: user_bool_exp!
    ): user_mutation_response
    "delete single row from the table: \"user\""
    delete_user_by_pk(id: Int!): user
    "insert data into the table: \"organization\""
    insert_organization(
        "the rows to be inserted"
        objects: [organization_insert_input!]!,
        "on conflict condition"
        on_conflict: organization_on_conflict
    ): organization_mutation_response
    "insert data into the table: \"organization_invite_user\""
    insert_organization_invite_user(
        "the rows to be inserted"
        objects: [organization_invite_user_insert_input!]!,
        "on conflict condition"
        on_conflict: organization_invite_user_on_conflict
    ): organization_invite_user_mutation_response
    "insert a single row into the table: \"organization_invite_user\""
    insert_organization_invite_user_one(
        "the row to be inserted"
        object: organization_invite_user_insert_input!,
        "on conflict condition"
        on_conflict: organization_invite_user_on_conflict
    ): organization_invite_user
    "insert a single row into the table: \"organization\""
    insert_organization_one(
        "the row to be inserted"
        object: organization_insert_input!,
        "on conflict condition"
        on_conflict: organization_on_conflict
    ): organization
    "insert data into the table: \"project\""
    insert_project(
        "the rows to be inserted"
        objects: [project_insert_input!]!,
        "on conflict condition"
        on_conflict: project_on_conflict
    ): project_mutation_response
    "insert a single row into the table: \"project\""
    insert_project_one(
        "the row to be inserted"
        object: project_insert_input!,
        "on conflict condition"
        on_conflict: project_on_conflict
    ): project
    "insert data into the table: \"run\""
    insert_run(
        "the rows to be inserted"
        objects: [run_insert_input!]!,
        "on conflict condition"
        on_conflict: run_on_conflict
    ): run_mutation_response
    "insert a single row into the table: \"run\""
    insert_run_one(
        "the row to be inserted"
        object: run_insert_input!,
        "on conflict condition"
        on_conflict: run_on_conflict
    ): run
    "insert data into the table: \"run_path\""
    insert_run_path(
        "the rows to be inserted"
        objects: [run_path_insert_input!]!,
        "on conflict condition"
        on_conflict: run_path_on_conflict
    ): run_path_mutation_response
    "insert a single row into the table: \"run_path\""
    insert_run_path_one(
        "the row to be inserted"
        object: run_path_insert_input!,
        "on conflict condition"
        on_conflict: run_path_on_conflict
    ): run_path
    "insert data into the table: \"user\""
    insert_user(
        "the rows to be inserted"
        objects: [user_insert_input!]!,
        "on conflict condition"
        on_conflict: user_on_conflict
    ): user_mutation_response
    "insert a single row into the table: \"user\""
    insert_user_one(
        "the row to be inserted"
        object: user_insert_input!,
        "on conflict condition"
        on_conflict: user_on_conflict
    ): user
    "update data of the table: \"organization\""
    update_organization(
        "increments the integer columns with given value of the filtered values"
        _inc: organization_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: organization_set_input,
        "filter the rows which have to be updated"
        where: organization_bool_exp!
    ): organization_mutation_response
    "update single row of the table: \"organization\""
    update_organization_by_pk(
        "increments the integer columns with given value of the filtered values"
        _inc: organization_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: organization_set_input,
        pk_columns: organization_pk_columns_input!
    ): organization
    "update data of the table: \"organization_invite_user\""
    update_organization_invite_user(
        "increments the integer columns with given value of the filtered values"
        _inc: organization_invite_user_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: organization_invite_user_set_input,
        "filter the rows which have to be updated"
        where: organization_invite_user_bool_exp!
    ): organization_invite_user_mutation_response
    "update single row of the table: \"organization_invite_user\""
    update_organization_invite_user_by_pk(
        "increments the integer columns with given value of the filtered values"
        _inc: organization_invite_user_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: organization_invite_user_set_input,
        pk_columns: organization_invite_user_pk_columns_input!
    ): organization_invite_user
    "update data of the table: \"project\""
    update_project(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: project_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: project_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: project_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: project_delete_key_input,
        "increments the integer columns with given value of the filtered values"
        _inc: project_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: project_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: project_set_input,
        "filter the rows which have to be updated"
        where: project_bool_exp!
    ): project_mutation_response
    "update single row of the table: \"project\""
    update_project_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: project_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: project_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: project_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: project_delete_key_input,
        "increments the integer columns with given value of the filtered values"
        _inc: project_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: project_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: project_set_input,
        pk_columns: project_pk_columns_input!
    ): project
    "update data of the table: \"run\""
    update_run(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: run_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: run_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: run_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: run_delete_key_input,
        "increments the integer columns with given value of the filtered values"
        _inc: run_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: run_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: run_set_input,
        "filter the rows which have to be updated"
        where: run_bool_exp!
    ): run_mutation_response
    "update single row of the table: \"run\""
    update_run_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: run_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: run_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: run_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: run_delete_key_input,
        "increments the integer columns with given value of the filtered values"
        _inc: run_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: run_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: run_set_input,
        pk_columns: run_pk_columns_input!
    ): run
    "update data of the table: \"run_path\""
    update_run_path(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: run_path_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: run_path_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: run_path_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: run_path_delete_key_input,
        "increments the integer columns with given value of the filtered values"
        _inc: run_path_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: run_path_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: run_path_set_input,
        "filter the rows which have to be updated"
        where: run_path_bool_exp!
    ): run_path_mutation_response
    "update single row of the table: \"run_path\""
    update_run_path_by_pk(
        "append existing jsonb value of filtered columns with new jsonb value"
        _append: run_path_append_input,
        "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
        _delete_at_path: run_path_delete_at_path_input,
        "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
        _delete_elem: run_path_delete_elem_input,
        "delete key/value pair or string element. key/value pairs are matched based on their key value"
        _delete_key: run_path_delete_key_input,
        "increments the integer columns with given value of the filtered values"
        _inc: run_path_inc_input,
        "prepend existing jsonb value of filtered columns with new jsonb value"
        _prepend: run_path_prepend_input,
        "sets the columns of the filtered rows to the given values"
        _set: run_path_set_input,
        pk_columns: run_path_pk_columns_input!
    ): run_path
    "update data of the table: \"user\""
    update_user(
        "increments the integer columns with given value of the filtered values"
        _inc: user_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: user_set_input,
        "filter the rows which have to be updated"
        where: user_bool_exp!
    ): user_mutation_response
    "update single row of the table: \"user\""
    update_user_by_pk(
        "increments the integer columns with given value of the filtered values"
        _inc: user_inc_input,
        "sets the columns of the filtered rows to the given values"
        _set: user_set_input,
        pk_columns: user_pk_columns_input!
    ): user
}

"columns and relationships of \"organization\""
type organization {
    id: Int!
    "An array relationship"
    invited_users(
        "distinct select on columns"
        distinct_on: [organization_invite_user_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_invite_user_order_by!],
        "filter the rows returned"
        where: organization_invite_user_bool_exp
    ): [organization_invite_user!]!
    "An aggregated array relationship"
    invited_users_aggregate(
        "distinct select on columns"
        distinct_on: [organization_invite_user_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_invite_user_order_by!],
        "filter the rows returned"
        where: organization_invite_user_bool_exp
    ): organization_invite_user_aggregate!
    name: String!
    "An object relationship"
    owner: user!
    owner_id: Int!
    "An array relationship"
    projects(
        "distinct select on columns"
        distinct_on: [project_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [project_order_by!],
        "filter the rows returned"
        where: project_bool_exp
    ): [project!]!
    "An aggregated array relationship"
    projects_aggregate(
        "distinct select on columns"
        distinct_on: [project_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [project_order_by!],
        "filter the rows returned"
        where: project_bool_exp
    ): project_aggregate!
    slug: String!
}

"aggregated selection of \"organization\""
type organization_aggregate {
    aggregate: organization_aggregate_fields
    nodes: [organization!]!
}

"aggregate fields of \"organization\""
type organization_aggregate_fields {
    avg: organization_avg_fields
    count(columns: [organization_select_column!], distinct: Boolean): Int
    max: organization_max_fields
    min: organization_min_fields
    stddev: organization_stddev_fields
    stddev_pop: organization_stddev_pop_fields
    stddev_samp: organization_stddev_samp_fields
    sum: organization_sum_fields
    var_pop: organization_var_pop_fields
    var_samp: organization_var_samp_fields
    variance: organization_variance_fields
}

"aggregate avg on columns"
type organization_avg_fields {
    id: Float
    owner_id: Float
}

"columns and relationships of \"organization_invite_user\""
type organization_invite_user {
    created_at: timestamptz!
    email: String!
    id: Int!
    invite_token: uuid!
    "An object relationship"
    organization: organization!
    organization_id: Int!
}

"aggregated selection of \"organization_invite_user\""
type organization_invite_user_aggregate {
    aggregate: organization_invite_user_aggregate_fields
    nodes: [organization_invite_user!]!
}

"aggregate fields of \"organization_invite_user\""
type organization_invite_user_aggregate_fields {
    avg: organization_invite_user_avg_fields
    count(columns: [organization_invite_user_select_column!], distinct: Boolean): Int
    max: organization_invite_user_max_fields
    min: organization_invite_user_min_fields
    stddev: organization_invite_user_stddev_fields
    stddev_pop: organization_invite_user_stddev_pop_fields
    stddev_samp: organization_invite_user_stddev_samp_fields
    sum: organization_invite_user_sum_fields
    var_pop: organization_invite_user_var_pop_fields
    var_samp: organization_invite_user_var_samp_fields
    variance: organization_invite_user_variance_fields
}

"aggregate avg on columns"
type organization_invite_user_avg_fields {
    id: Float
    organization_id: Float
}

"aggregate max on columns"
type organization_invite_user_max_fields {
    created_at: timestamptz
    email: String
    id: Int
    invite_token: uuid
    organization_id: Int
}

"aggregate min on columns"
type organization_invite_user_min_fields {
    created_at: timestamptz
    email: String
    id: Int
    invite_token: uuid
    organization_id: Int
}

"response of any mutation on the table \"organization_invite_user\""
type organization_invite_user_mutation_response {
    "number of affected rows by the mutation"
    affected_rows: Int!
    "data of the affected rows by the mutation"
    returning: [organization_invite_user!]!
}

"aggregate stddev on columns"
type organization_invite_user_stddev_fields {
    id: Float
    organization_id: Float
}

"aggregate stddev_pop on columns"
type organization_invite_user_stddev_pop_fields {
    id: Float
    organization_id: Float
}

"aggregate stddev_samp on columns"
type organization_invite_user_stddev_samp_fields {
    id: Float
    organization_id: Float
}

"aggregate sum on columns"
type organization_invite_user_sum_fields {
    id: Int
    organization_id: Int
}

"aggregate var_pop on columns"
type organization_invite_user_var_pop_fields {
    id: Float
    organization_id: Float
}

"aggregate var_samp on columns"
type organization_invite_user_var_samp_fields {
    id: Float
    organization_id: Float
}

"aggregate variance on columns"
type organization_invite_user_variance_fields {
    id: Float
    organization_id: Float
}

"aggregate max on columns"
type organization_max_fields {
    id: Int
    name: String
    owner_id: Int
    slug: String
}

"aggregate min on columns"
type organization_min_fields {
    id: Int
    name: String
    owner_id: Int
    slug: String
}

"response of any mutation on the table \"organization\""
type organization_mutation_response {
    "number of affected rows by the mutation"
    affected_rows: Int!
    "data of the affected rows by the mutation"
    returning: [organization!]!
}

"aggregate stddev on columns"
type organization_stddev_fields {
    id: Float
    owner_id: Float
}

"aggregate stddev_pop on columns"
type organization_stddev_pop_fields {
    id: Float
    owner_id: Float
}

"aggregate stddev_samp on columns"
type organization_stddev_samp_fields {
    id: Float
    owner_id: Float
}

"aggregate sum on columns"
type organization_sum_fields {
    id: Int
    owner_id: Int
}

"aggregate var_pop on columns"
type organization_var_pop_fields {
    id: Float
    owner_id: Float
}

"aggregate var_samp on columns"
type organization_var_samp_fields {
    id: Float
    owner_id: Float
}

"aggregate variance on columns"
type organization_variance_fields {
    id: Float
    owner_id: Float
}

"columns and relationships of \"project\""
type project {
    graph(
        "JSON select path"
        path: String
    ): jsonb
    id: Int!
    name: String!
    "An object relationship"
    organization: organization!
    organization_id: Int!
    "An array relationship"
    run(
        "distinct select on columns"
        distinct_on: [run_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_order_by!],
        "filter the rows returned"
        where: run_bool_exp
    ): [run!]!
    "An aggregated array relationship"
    run_aggregate(
        "distinct select on columns"
        distinct_on: [run_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_order_by!],
        "filter the rows returned"
        where: run_bool_exp
    ): run_aggregate!
    settings(
        "JSON select path"
        path: String
    ): jsonb
    slug: String!
}

"aggregated selection of \"project\""
type project_aggregate {
    aggregate: project_aggregate_fields
    nodes: [project!]!
}

"aggregate fields of \"project\""
type project_aggregate_fields {
    avg: project_avg_fields
    count(columns: [project_select_column!], distinct: Boolean): Int
    max: project_max_fields
    min: project_min_fields
    stddev: project_stddev_fields
    stddev_pop: project_stddev_pop_fields
    stddev_samp: project_stddev_samp_fields
    sum: project_sum_fields
    var_pop: project_var_pop_fields
    var_samp: project_var_samp_fields
    variance: project_variance_fields
}

"aggregate avg on columns"
type project_avg_fields {
    id: Float
    organization_id: Float
}

"aggregate max on columns"
type project_max_fields {
    id: Int
    name: String
    organization_id: Int
    slug: String
}

"aggregate min on columns"
type project_min_fields {
    id: Int
    name: String
    organization_id: Int
    slug: String
}

"response of any mutation on the table \"project\""
type project_mutation_response {
    "number of affected rows by the mutation"
    affected_rows: Int!
    "data of the affected rows by the mutation"
    returning: [project!]!
}

"aggregate stddev on columns"
type project_stddev_fields {
    id: Float
    organization_id: Float
}

"aggregate stddev_pop on columns"
type project_stddev_pop_fields {
    id: Float
    organization_id: Float
}

"aggregate stddev_samp on columns"
type project_stddev_samp_fields {
    id: Float
    organization_id: Float
}

"aggregate sum on columns"
type project_sum_fields {
    id: Int
    organization_id: Int
}

"aggregate var_pop on columns"
type project_var_pop_fields {
    id: Float
    organization_id: Float
}

"aggregate var_samp on columns"
type project_var_samp_fields {
    id: Float
    organization_id: Float
}

"aggregate variance on columns"
type project_variance_fields {
    id: Float
    organization_id: Float
}

"query root"
type query_root {
    "fetch data from the table: \"organization\""
    organization(
        "distinct select on columns"
        distinct_on: [organization_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_order_by!],
        "filter the rows returned"
        where: organization_bool_exp
    ): [organization!]!
    "fetch aggregated fields from the table: \"organization\""
    organization_aggregate(
        "distinct select on columns"
        distinct_on: [organization_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_order_by!],
        "filter the rows returned"
        where: organization_bool_exp
    ): organization_aggregate!
    "fetch data from the table: \"organization\" using primary key columns"
    organization_by_pk(id: Int!): organization
    "fetch data from the table: \"organization_invite_user\""
    organization_invite_user(
        "distinct select on columns"
        distinct_on: [organization_invite_user_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_invite_user_order_by!],
        "filter the rows returned"
        where: organization_invite_user_bool_exp
    ): [organization_invite_user!]!
    "fetch aggregated fields from the table: \"organization_invite_user\""
    organization_invite_user_aggregate(
        "distinct select on columns"
        distinct_on: [organization_invite_user_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_invite_user_order_by!],
        "filter the rows returned"
        where: organization_invite_user_bool_exp
    ): organization_invite_user_aggregate!
    "fetch data from the table: \"organization_invite_user\" using primary key columns"
    organization_invite_user_by_pk(id: Int!): organization_invite_user
    "fetch data from the table: \"project\""
    project(
        "distinct select on columns"
        distinct_on: [project_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [project_order_by!],
        "filter the rows returned"
        where: project_bool_exp
    ): [project!]!
    "fetch aggregated fields from the table: \"project\""
    project_aggregate(
        "distinct select on columns"
        distinct_on: [project_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [project_order_by!],
        "filter the rows returned"
        where: project_bool_exp
    ): project_aggregate!
    "fetch data from the table: \"project\" using primary key columns"
    project_by_pk(id: Int!): project
    "fetch data from the table: \"run\""
    run(
        "distinct select on columns"
        distinct_on: [run_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_order_by!],
        "filter the rows returned"
        where: run_bool_exp
    ): [run!]!
    "fetch aggregated fields from the table: \"run\""
    run_aggregate(
        "distinct select on columns"
        distinct_on: [run_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_order_by!],
        "filter the rows returned"
        where: run_bool_exp
    ): run_aggregate!
    "fetch data from the table: \"run\" using primary key columns"
    run_by_pk(id: bigint!): run
    "fetch data from the table: \"run_path\""
    run_path(
        "distinct select on columns"
        distinct_on: [run_path_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_path_order_by!],
        "filter the rows returned"
        where: run_path_bool_exp
    ): [run_path!]!
    "fetch aggregated fields from the table: \"run_path\""
    run_path_aggregate(
        "distinct select on columns"
        distinct_on: [run_path_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_path_order_by!],
        "filter the rows returned"
        where: run_path_bool_exp
    ): run_path_aggregate!
    "fetch data from the table: \"run_path\" using primary key columns"
    run_path_by_pk(id: bigint!): run_path
    "fetch data from the table: \"user\""
    user(
        "distinct select on columns"
        distinct_on: [user_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [user_order_by!],
        "filter the rows returned"
        where: user_bool_exp
    ): [user!]!
    "fetch aggregated fields from the table: \"user\""
    user_aggregate(
        "distinct select on columns"
        distinct_on: [user_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [user_order_by!],
        "filter the rows returned"
        where: user_bool_exp
    ): user_aggregate!
    "fetch data from the table: \"user\" using primary key columns"
    user_by_pk(id: Int!): user
}

"columns and relationships of \"run\""
type run {
    "A computed field, executes function \"run_blocks_runned\""
    blocks_runned: Int
    finished_at: timestamptz
    graph(
        "JSON select path"
        path: String
    ): jsonb
    id: bigint!
    "An array relationship"
    paths(
        "distinct select on columns"
        distinct_on: [run_path_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_path_order_by!],
        "filter the rows returned"
        where: run_path_bool_exp
    ): [run_path!]!
    "An aggregated array relationship"
    paths_aggregate(
        "distinct select on columns"
        distinct_on: [run_path_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_path_order_by!],
        "filter the rows returned"
        where: run_path_bool_exp
    ): run_path_aggregate!
    "An object relationship"
    project: project!
    project_id: Int!
    run_by_user: Int!
    settings(
        "JSON select path"
        path: String
    ): jsonb
    started_at: timestamptz!
}

"aggregated selection of \"run\""
type run_aggregate {
    aggregate: run_aggregate_fields
    nodes: [run!]!
}

"aggregate fields of \"run\""
type run_aggregate_fields {
    avg: run_avg_fields
    count(columns: [run_select_column!], distinct: Boolean): Int
    max: run_max_fields
    min: run_min_fields
    stddev: run_stddev_fields
    stddev_pop: run_stddev_pop_fields
    stddev_samp: run_stddev_samp_fields
    sum: run_sum_fields
    var_pop: run_var_pop_fields
    var_samp: run_var_samp_fields
    variance: run_variance_fields
}

"aggregate avg on columns"
type run_avg_fields {
    id: Float
    project_id: Float
    run_by_user: Float
}

"aggregate max on columns"
type run_max_fields {
    finished_at: timestamptz
    id: bigint
    project_id: Int
    run_by_user: Int
    started_at: timestamptz
}

"aggregate min on columns"
type run_min_fields {
    finished_at: timestamptz
    id: bigint
    project_id: Int
    run_by_user: Int
    started_at: timestamptz
}

"response of any mutation on the table \"run\""
type run_mutation_response {
    "number of affected rows by the mutation"
    affected_rows: Int!
    "data of the affected rows by the mutation"
    returning: [run!]!
}

"columns and relationships of \"run_path\""
type run_path {
    "A computed field, executes function \"run_path_blocks_total\""
    blocks_count: Int
    "A computed field, executes function \"run_path_blocks_failed\""
    blocks_failed: Int
    "A computed field, executes function \"run_path_blocks_success\""
    blocks_success: Int
    edges(
        "JSON select path"
        path: String
    ): jsonb!
    finished_at: timestamptz
    id: bigint!
    "An object relationship"
    run: run!
    run_id: bigint!
    settings(
        "JSON select path"
        path: String
    ): jsonb
    started_at: timestamptz!
}

"aggregated selection of \"run_path\""
type run_path_aggregate {
    aggregate: run_path_aggregate_fields
    nodes: [run_path!]!
}

"aggregate fields of \"run_path\""
type run_path_aggregate_fields {
    avg: run_path_avg_fields
    count(columns: [run_path_select_column!], distinct: Boolean): Int
    max: run_path_max_fields
    min: run_path_min_fields
    stddev: run_path_stddev_fields
    stddev_pop: run_path_stddev_pop_fields
    stddev_samp: run_path_stddev_samp_fields
    sum: run_path_sum_fields
    var_pop: run_path_var_pop_fields
    var_samp: run_path_var_samp_fields
    variance: run_path_variance_fields
}

"aggregate avg on columns"
type run_path_avg_fields {
    id: Float
    run_id: Float
}

"aggregate max on columns"
type run_path_max_fields {
    finished_at: timestamptz
    id: bigint
    run_id: bigint
    started_at: timestamptz
}

"aggregate min on columns"
type run_path_min_fields {
    finished_at: timestamptz
    id: bigint
    run_id: bigint
    started_at: timestamptz
}

"response of any mutation on the table \"run_path\""
type run_path_mutation_response {
    "number of affected rows by the mutation"
    affected_rows: Int!
    "data of the affected rows by the mutation"
    returning: [run_path!]!
}

"aggregate stddev on columns"
type run_path_stddev_fields {
    id: Float
    run_id: Float
}

"aggregate stddev_pop on columns"
type run_path_stddev_pop_fields {
    id: Float
    run_id: Float
}

"aggregate stddev_samp on columns"
type run_path_stddev_samp_fields {
    id: Float
    run_id: Float
}

"aggregate sum on columns"
type run_path_sum_fields {
    id: bigint
    run_id: bigint
}

"aggregate var_pop on columns"
type run_path_var_pop_fields {
    id: Float
    run_id: Float
}

"aggregate var_samp on columns"
type run_path_var_samp_fields {
    id: Float
    run_id: Float
}

"aggregate variance on columns"
type run_path_variance_fields {
    id: Float
    run_id: Float
}

"aggregate stddev on columns"
type run_stddev_fields {
    id: Float
    project_id: Float
    run_by_user: Float
}

"aggregate stddev_pop on columns"
type run_stddev_pop_fields {
    id: Float
    project_id: Float
    run_by_user: Float
}

"aggregate stddev_samp on columns"
type run_stddev_samp_fields {
    id: Float
    project_id: Float
    run_by_user: Float
}

"aggregate sum on columns"
type run_sum_fields {
    id: bigint
    project_id: Int
    run_by_user: Int
}

"aggregate var_pop on columns"
type run_var_pop_fields {
    id: Float
    project_id: Float
    run_by_user: Float
}

"aggregate var_samp on columns"
type run_var_samp_fields {
    id: Float
    project_id: Float
    run_by_user: Float
}

"aggregate variance on columns"
type run_variance_fields {
    id: Float
    project_id: Float
    run_by_user: Float
}

"subscription root"
type subscription_root {
    "fetch data from the table: \"organization\""
    organization(
        "distinct select on columns"
        distinct_on: [organization_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_order_by!],
        "filter the rows returned"
        where: organization_bool_exp
    ): [organization!]!
    "fetch aggregated fields from the table: \"organization\""
    organization_aggregate(
        "distinct select on columns"
        distinct_on: [organization_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_order_by!],
        "filter the rows returned"
        where: organization_bool_exp
    ): organization_aggregate!
    "fetch data from the table: \"organization\" using primary key columns"
    organization_by_pk(id: Int!): organization
    "fetch data from the table: \"organization_invite_user\""
    organization_invite_user(
        "distinct select on columns"
        distinct_on: [organization_invite_user_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_invite_user_order_by!],
        "filter the rows returned"
        where: organization_invite_user_bool_exp
    ): [organization_invite_user!]!
    "fetch aggregated fields from the table: \"organization_invite_user\""
    organization_invite_user_aggregate(
        "distinct select on columns"
        distinct_on: [organization_invite_user_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_invite_user_order_by!],
        "filter the rows returned"
        where: organization_invite_user_bool_exp
    ): organization_invite_user_aggregate!
    "fetch data from the table: \"organization_invite_user\" using primary key columns"
    organization_invite_user_by_pk(id: Int!): organization_invite_user
    "fetch data from the table: \"project\""
    project(
        "distinct select on columns"
        distinct_on: [project_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [project_order_by!],
        "filter the rows returned"
        where: project_bool_exp
    ): [project!]!
    "fetch aggregated fields from the table: \"project\""
    project_aggregate(
        "distinct select on columns"
        distinct_on: [project_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [project_order_by!],
        "filter the rows returned"
        where: project_bool_exp
    ): project_aggregate!
    "fetch data from the table: \"project\" using primary key columns"
    project_by_pk(id: Int!): project
    "fetch data from the table: \"run\""
    run(
        "distinct select on columns"
        distinct_on: [run_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_order_by!],
        "filter the rows returned"
        where: run_bool_exp
    ): [run!]!
    "fetch aggregated fields from the table: \"run\""
    run_aggregate(
        "distinct select on columns"
        distinct_on: [run_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_order_by!],
        "filter the rows returned"
        where: run_bool_exp
    ): run_aggregate!
    "fetch data from the table: \"run\" using primary key columns"
    run_by_pk(id: bigint!): run
    "fetch data from the table: \"run_path\""
    run_path(
        "distinct select on columns"
        distinct_on: [run_path_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_path_order_by!],
        "filter the rows returned"
        where: run_path_bool_exp
    ): [run_path!]!
    "fetch aggregated fields from the table: \"run_path\""
    run_path_aggregate(
        "distinct select on columns"
        distinct_on: [run_path_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [run_path_order_by!],
        "filter the rows returned"
        where: run_path_bool_exp
    ): run_path_aggregate!
    "fetch data from the table: \"run_path\" using primary key columns"
    run_path_by_pk(id: bigint!): run_path
    "fetch data from the table: \"user\""
    user(
        "distinct select on columns"
        distinct_on: [user_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [user_order_by!],
        "filter the rows returned"
        where: user_bool_exp
    ): [user!]!
    "fetch aggregated fields from the table: \"user\""
    user_aggregate(
        "distinct select on columns"
        distinct_on: [user_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [user_order_by!],
        "filter the rows returned"
        where: user_bool_exp
    ): user_aggregate!
    "fetch data from the table: \"user\" using primary key columns"
    user_by_pk(id: Int!): user
}

"columns and relationships of \"user\""
type user {
    firebase_id: String!
    id: Int!
    name: String!
    "An array relationship"
    owner_of_organizations(
        "distinct select on columns"
        distinct_on: [organization_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_order_by!],
        "filter the rows returned"
        where: organization_bool_exp
    ): [organization!]!
    "An aggregated array relationship"
    owner_of_organizations_aggregate(
        "distinct select on columns"
        distinct_on: [organization_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [organization_order_by!],
        "filter the rows returned"
        where: organization_bool_exp
    ): organization_aggregate!
}

"aggregated selection of \"user\""
type user_aggregate {
    aggregate: user_aggregate_fields
    nodes: [user!]!
}

"aggregate fields of \"user\""
type user_aggregate_fields {
    avg: user_avg_fields
    count(columns: [user_select_column!], distinct: Boolean): Int
    max: user_max_fields
    min: user_min_fields
    stddev: user_stddev_fields
    stddev_pop: user_stddev_pop_fields
    stddev_samp: user_stddev_samp_fields
    sum: user_sum_fields
    var_pop: user_var_pop_fields
    var_samp: user_var_samp_fields
    variance: user_variance_fields
}

"aggregate avg on columns"
type user_avg_fields {
    id: Float
}

"aggregate max on columns"
type user_max_fields {
    firebase_id: String
    id: Int
    name: String
}

"aggregate min on columns"
type user_min_fields {
    firebase_id: String
    id: Int
    name: String
}

"response of any mutation on the table \"user\""
type user_mutation_response {
    "number of affected rows by the mutation"
    affected_rows: Int!
    "data of the affected rows by the mutation"
    returning: [user!]!
}

"aggregate stddev on columns"
type user_stddev_fields {
    id: Float
}

"aggregate stddev_pop on columns"
type user_stddev_pop_fields {
    id: Float
}

"aggregate stddev_samp on columns"
type user_stddev_samp_fields {
    id: Float
}

"aggregate sum on columns"
type user_sum_fields {
    id: Int
}

"aggregate var_pop on columns"
type user_var_pop_fields {
    id: Float
}

"aggregate var_samp on columns"
type user_var_samp_fields {
    id: Float
}

"aggregate variance on columns"
type user_variance_fields {
    id: Float
}

"column ordering options"
enum order_by {
    "in the ascending order, nulls last"
    asc
    "in the ascending order, nulls first"
    asc_nulls_first
    "in the ascending order, nulls last"
    asc_nulls_last
    "in the descending order, nulls first"
    desc
    "in the descending order, nulls first"
    desc_nulls_first
    "in the descending order, nulls last"
    desc_nulls_last
}

"unique or primary key constraints on table \"organization\""
enum organization_constraint {
    "unique or primary key constraint"
    organization_name_key
    "unique or primary key constraint"
    organization_pkey
    "unique or primary key constraint"
    organization_slug_key
}

"unique or primary key constraints on table \"organization_invite_user\""
enum organization_invite_user_constraint {
    "unique or primary key constraint"
    organization_invite_user_email_key
    "unique or primary key constraint"
    organization_invite_user_pkey
}

"select columns of table \"organization_invite_user\""
enum organization_invite_user_select_column {
    "column name"
    created_at
    "column name"
    email
    "column name"
    id
    "column name"
    invite_token
    "column name"
    organization_id
}

"update columns of table \"organization_invite_user\""
enum organization_invite_user_update_column {
    "column name"
    created_at
    "column name"
    email
    "column name"
    id
    "column name"
    invite_token
    "column name"
    organization_id
}

"select columns of table \"organization\""
enum organization_select_column {
    "column name"
    id
    "column name"
    name
    "column name"
    owner_id
    "column name"
    slug
}

"update columns of table \"organization\""
enum organization_update_column {
    "column name"
    id
    "column name"
    name
    "column name"
    owner_id
    "column name"
    slug
}

"unique or primary key constraints on table \"project\""
enum project_constraint {
    "unique or primary key constraint"
    project_organization_id_name_key
    "unique or primary key constraint"
    project_organization_id_slug_key
    "unique or primary key constraint"
    project_pkey
}

"select columns of table \"project\""
enum project_select_column {
    "column name"
    graph
    "column name"
    id
    "column name"
    name
    "column name"
    organization_id
    "column name"
    settings
    "column name"
    slug
}

"update columns of table \"project\""
enum project_update_column {
    "column name"
    graph
    "column name"
    id
    "column name"
    name
    "column name"
    organization_id
    "column name"
    settings
    "column name"
    slug
}

"unique or primary key constraints on table \"run\""
enum run_constraint {
    "unique or primary key constraint"
    run_history_pkey
}

"unique or primary key constraints on table \"run_path\""
enum run_path_constraint {
    "unique or primary key constraint"
    run_path_pkey
}

"select columns of table \"run_path\""
enum run_path_select_column {
    "column name"
    edges
    "column name"
    finished_at
    "column name"
    id
    "column name"
    run_id
    "column name"
    settings
    "column name"
    started_at
}

"update columns of table \"run_path\""
enum run_path_update_column {
    "column name"
    edges
    "column name"
    finished_at
    "column name"
    id
    "column name"
    run_id
    "column name"
    settings
    "column name"
    started_at
}

"select columns of table \"run\""
enum run_select_column {
    "column name"
    finished_at
    "column name"
    graph
    "column name"
    id
    "column name"
    project_id
    "column name"
    run_by_user
    "column name"
    settings
    "column name"
    started_at
}

"update columns of table \"run\""
enum run_update_column {
    "column name"
    finished_at
    "column name"
    graph
    "column name"
    id
    "column name"
    project_id
    "column name"
    run_by_user
    "column name"
    settings
    "column name"
    started_at
}

"unique or primary key constraints on table \"user\""
enum user_constraint {
    "unique or primary key constraint"
    user_firebase_id_key
    "unique or primary key constraint"
    user_pkey
}

"select columns of table \"user\""
enum user_select_column {
    "column name"
    firebase_id
    "column name"
    id
    "column name"
    name
}

"update columns of table \"user\""
enum user_update_column {
    "column name"
    firebase_id
    "column name"
    id
    "column name"
    name
}

"expression to compare columns of type Int. All fields are combined with logical 'AND'."
input Int_comparison_exp {
    _eq: Int
    _gt: Int
    _gte: Int
    _in: [Int!]
    _is_null: Boolean
    _lt: Int
    _lte: Int
    _neq: Int
    _nin: [Int!]
}

"expression to compare columns of type String. All fields are combined with logical 'AND'."
input String_comparison_exp {
    _eq: String
    _gt: String
    _gte: String
    _ilike: String
    _in: [String!]
    _is_null: Boolean
    _like: String
    _lt: String
    _lte: String
    _neq: String
    _nilike: String
    _nin: [String!]
    _nlike: String
    _nsimilar: String
    _similar: String
}

"expression to compare columns of type bigint. All fields are combined with logical 'AND'."
input bigint_comparison_exp {
    _eq: bigint
    _gt: bigint
    _gte: bigint
    _in: [bigint!]
    _is_null: Boolean
    _lt: bigint
    _lte: bigint
    _neq: bigint
    _nin: [bigint!]
}

"expression to compare columns of type jsonb. All fields are combined with logical 'AND'."
input jsonb_comparison_exp {
    "is the column contained in the given json value"
    _contained_in: jsonb
    "does the column contain the given json value at the top level"
    _contains: jsonb
    _eq: jsonb
    _gt: jsonb
    _gte: jsonb
    "does the string exist as a top-level key in the column"
    _has_key: String
    "do all of these strings exist as top-level keys in the column"
    _has_keys_all: [String!]
    "do any of these strings exist as top-level keys in the column"
    _has_keys_any: [String!]
    _in: [jsonb!]
    _is_null: Boolean
    _lt: jsonb
    _lte: jsonb
    _neq: jsonb
    _nin: [jsonb!]
}

"order by aggregate values of table \"organization\""
input organization_aggregate_order_by {
    avg: organization_avg_order_by
    count: order_by
    max: organization_max_order_by
    min: organization_min_order_by
    stddev: organization_stddev_order_by
    stddev_pop: organization_stddev_pop_order_by
    stddev_samp: organization_stddev_samp_order_by
    sum: organization_sum_order_by
    var_pop: organization_var_pop_order_by
    var_samp: organization_var_samp_order_by
    variance: organization_variance_order_by
}

"input type for inserting array relation for remote table \"organization\""
input organization_arr_rel_insert_input {
    data: [organization_insert_input!]!
    on_conflict: organization_on_conflict
}

"order by avg() on columns of table \"organization\""
input organization_avg_order_by {
    id: order_by
    owner_id: order_by
}

"Boolean expression to filter rows from the table \"organization\". All fields are combined with a logical 'AND'."
input organization_bool_exp {
    _and: [organization_bool_exp]
    _not: organization_bool_exp
    _or: [organization_bool_exp]
    id: Int_comparison_exp
    invited_users: organization_invite_user_bool_exp
    name: String_comparison_exp
    owner: user_bool_exp
    owner_id: Int_comparison_exp
    projects: project_bool_exp
    slug: String_comparison_exp
}

"input type for incrementing integer column in table \"organization\""
input organization_inc_input {
    id: Int
    owner_id: Int
}

"input type for inserting data into table \"organization\""
input organization_insert_input {
    id: Int
    invited_users: organization_invite_user_arr_rel_insert_input
    name: String
    owner: user_obj_rel_insert_input
    owner_id: Int
    projects: project_arr_rel_insert_input
    slug: String
}

"order by aggregate values of table \"organization_invite_user\""
input organization_invite_user_aggregate_order_by {
    avg: organization_invite_user_avg_order_by
    count: order_by
    max: organization_invite_user_max_order_by
    min: organization_invite_user_min_order_by
    stddev: organization_invite_user_stddev_order_by
    stddev_pop: organization_invite_user_stddev_pop_order_by
    stddev_samp: organization_invite_user_stddev_samp_order_by
    sum: organization_invite_user_sum_order_by
    var_pop: organization_invite_user_var_pop_order_by
    var_samp: organization_invite_user_var_samp_order_by
    variance: organization_invite_user_variance_order_by
}

"input type for inserting array relation for remote table \"organization_invite_user\""
input organization_invite_user_arr_rel_insert_input {
    data: [organization_invite_user_insert_input!]!
    on_conflict: organization_invite_user_on_conflict
}

"order by avg() on columns of table \"organization_invite_user\""
input organization_invite_user_avg_order_by {
    id: order_by
    organization_id: order_by
}

"Boolean expression to filter rows from the table \"organization_invite_user\". All fields are combined with a logical 'AND'."
input organization_invite_user_bool_exp {
    _and: [organization_invite_user_bool_exp]
    _not: organization_invite_user_bool_exp
    _or: [organization_invite_user_bool_exp]
    created_at: timestamptz_comparison_exp
    email: String_comparison_exp
    id: Int_comparison_exp
    invite_token: uuid_comparison_exp
    organization: organization_bool_exp
    organization_id: Int_comparison_exp
}

"input type for incrementing integer column in table \"organization_invite_user\""
input organization_invite_user_inc_input {
    id: Int
    organization_id: Int
}

"input type for inserting data into table \"organization_invite_user\""
input organization_invite_user_insert_input {
    created_at: timestamptz
    email: String
    id: Int
    invite_token: uuid
    organization: organization_obj_rel_insert_input
    organization_id: Int
}

"order by max() on columns of table \"organization_invite_user\""
input organization_invite_user_max_order_by {
    created_at: order_by
    email: order_by
    id: order_by
    invite_token: order_by
    organization_id: order_by
}

"order by min() on columns of table \"organization_invite_user\""
input organization_invite_user_min_order_by {
    created_at: order_by
    email: order_by
    id: order_by
    invite_token: order_by
    organization_id: order_by
}

"input type for inserting object relation for remote table \"organization_invite_user\""
input organization_invite_user_obj_rel_insert_input {
    data: organization_invite_user_insert_input!
    on_conflict: organization_invite_user_on_conflict
}

"on conflict condition type for table \"organization_invite_user\""
input organization_invite_user_on_conflict {
    constraint: organization_invite_user_constraint!
    update_columns: [organization_invite_user_update_column!]!
    where: organization_invite_user_bool_exp
}

"ordering options when selecting data from \"organization_invite_user\""
input organization_invite_user_order_by {
    created_at: order_by
    email: order_by
    id: order_by
    invite_token: order_by
    organization: organization_order_by
    organization_id: order_by
}

"primary key columns input for table: \"organization_invite_user\""
input organization_invite_user_pk_columns_input {
    id: Int!
}

"input type for updating data in table \"organization_invite_user\""
input organization_invite_user_set_input {
    created_at: timestamptz
    email: String
    id: Int
    invite_token: uuid
    organization_id: Int
}

"order by stddev() on columns of table \"organization_invite_user\""
input organization_invite_user_stddev_order_by {
    id: order_by
    organization_id: order_by
}

"order by stddev_pop() on columns of table \"organization_invite_user\""
input organization_invite_user_stddev_pop_order_by {
    id: order_by
    organization_id: order_by
}

"order by stddev_samp() on columns of table \"organization_invite_user\""
input organization_invite_user_stddev_samp_order_by {
    id: order_by
    organization_id: order_by
}

"order by sum() on columns of table \"organization_invite_user\""
input organization_invite_user_sum_order_by {
    id: order_by
    organization_id: order_by
}

"order by var_pop() on columns of table \"organization_invite_user\""
input organization_invite_user_var_pop_order_by {
    id: order_by
    organization_id: order_by
}

"order by var_samp() on columns of table \"organization_invite_user\""
input organization_invite_user_var_samp_order_by {
    id: order_by
    organization_id: order_by
}

"order by variance() on columns of table \"organization_invite_user\""
input organization_invite_user_variance_order_by {
    id: order_by
    organization_id: order_by
}

"order by max() on columns of table \"organization\""
input organization_max_order_by {
    id: order_by
    name: order_by
    owner_id: order_by
    slug: order_by
}

"order by min() on columns of table \"organization\""
input organization_min_order_by {
    id: order_by
    name: order_by
    owner_id: order_by
    slug: order_by
}

"input type for inserting object relation for remote table \"organization\""
input organization_obj_rel_insert_input {
    data: organization_insert_input!
    on_conflict: organization_on_conflict
}

"on conflict condition type for table \"organization\""
input organization_on_conflict {
    constraint: organization_constraint!
    update_columns: [organization_update_column!]!
    where: organization_bool_exp
}

"ordering options when selecting data from \"organization\""
input organization_order_by {
    id: order_by
    invited_users_aggregate: organization_invite_user_aggregate_order_by
    name: order_by
    owner: user_order_by
    owner_id: order_by
    projects_aggregate: project_aggregate_order_by
    slug: order_by
}

"primary key columns input for table: \"organization\""
input organization_pk_columns_input {
    id: Int!
}

"input type for updating data in table \"organization\""
input organization_set_input {
    id: Int
    name: String
    owner_id: Int
    slug: String
}

"order by stddev() on columns of table \"organization\""
input organization_stddev_order_by {
    id: order_by
    owner_id: order_by
}

"order by stddev_pop() on columns of table \"organization\""
input organization_stddev_pop_order_by {
    id: order_by
    owner_id: order_by
}

"order by stddev_samp() on columns of table \"organization\""
input organization_stddev_samp_order_by {
    id: order_by
    owner_id: order_by
}

"order by sum() on columns of table \"organization\""
input organization_sum_order_by {
    id: order_by
    owner_id: order_by
}

"order by var_pop() on columns of table \"organization\""
input organization_var_pop_order_by {
    id: order_by
    owner_id: order_by
}

"order by var_samp() on columns of table \"organization\""
input organization_var_samp_order_by {
    id: order_by
    owner_id: order_by
}

"order by variance() on columns of table \"organization\""
input organization_variance_order_by {
    id: order_by
    owner_id: order_by
}

"order by aggregate values of table \"project\""
input project_aggregate_order_by {
    avg: project_avg_order_by
    count: order_by
    max: project_max_order_by
    min: project_min_order_by
    stddev: project_stddev_order_by
    stddev_pop: project_stddev_pop_order_by
    stddev_samp: project_stddev_samp_order_by
    sum: project_sum_order_by
    var_pop: project_var_pop_order_by
    var_samp: project_var_samp_order_by
    variance: project_variance_order_by
}

"append existing jsonb value of filtered columns with new jsonb value"
input project_append_input {
    graph: jsonb
    settings: jsonb
}

"input type for inserting array relation for remote table \"project\""
input project_arr_rel_insert_input {
    data: [project_insert_input!]!
    on_conflict: project_on_conflict
}

"order by avg() on columns of table \"project\""
input project_avg_order_by {
    id: order_by
    organization_id: order_by
}

"Boolean expression to filter rows from the table \"project\". All fields are combined with a logical 'AND'."
input project_bool_exp {
    _and: [project_bool_exp]
    _not: project_bool_exp
    _or: [project_bool_exp]
    graph: jsonb_comparison_exp
    id: Int_comparison_exp
    name: String_comparison_exp
    organization: organization_bool_exp
    organization_id: Int_comparison_exp
    run: run_bool_exp
    settings: jsonb_comparison_exp
    slug: String_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input project_delete_at_path_input {
    graph: [String]
    settings: [String]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input project_delete_elem_input {
    graph: Int
    settings: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input project_delete_key_input {
    graph: String
    settings: String
}

"input type for incrementing integer column in table \"project\""
input project_inc_input {
    id: Int
    organization_id: Int
}

"input type for inserting data into table \"project\""
input project_insert_input {
    graph: jsonb
    id: Int
    name: String
    organization: organization_obj_rel_insert_input
    organization_id: Int
    run: run_arr_rel_insert_input
    settings: jsonb
    slug: String
}

"order by max() on columns of table \"project\""
input project_max_order_by {
    id: order_by
    name: order_by
    organization_id: order_by
    slug: order_by
}

"order by min() on columns of table \"project\""
input project_min_order_by {
    id: order_by
    name: order_by
    organization_id: order_by
    slug: order_by
}

"input type for inserting object relation for remote table \"project\""
input project_obj_rel_insert_input {
    data: project_insert_input!
    on_conflict: project_on_conflict
}

"on conflict condition type for table \"project\""
input project_on_conflict {
    constraint: project_constraint!
    update_columns: [project_update_column!]!
    where: project_bool_exp
}

"ordering options when selecting data from \"project\""
input project_order_by {
    graph: order_by
    id: order_by
    name: order_by
    organization: organization_order_by
    organization_id: order_by
    run_aggregate: run_aggregate_order_by
    settings: order_by
    slug: order_by
}

"primary key columns input for table: \"project\""
input project_pk_columns_input {
    id: Int!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input project_prepend_input {
    graph: jsonb
    settings: jsonb
}

"input type for updating data in table \"project\""
input project_set_input {
    graph: jsonb
    id: Int
    name: String
    organization_id: Int
    settings: jsonb
    slug: String
}

"order by stddev() on columns of table \"project\""
input project_stddev_order_by {
    id: order_by
    organization_id: order_by
}

"order by stddev_pop() on columns of table \"project\""
input project_stddev_pop_order_by {
    id: order_by
    organization_id: order_by
}

"order by stddev_samp() on columns of table \"project\""
input project_stddev_samp_order_by {
    id: order_by
    organization_id: order_by
}

"order by sum() on columns of table \"project\""
input project_sum_order_by {
    id: order_by
    organization_id: order_by
}

"order by var_pop() on columns of table \"project\""
input project_var_pop_order_by {
    id: order_by
    organization_id: order_by
}

"order by var_samp() on columns of table \"project\""
input project_var_samp_order_by {
    id: order_by
    organization_id: order_by
}

"order by variance() on columns of table \"project\""
input project_variance_order_by {
    id: order_by
    organization_id: order_by
}

"order by aggregate values of table \"run\""
input run_aggregate_order_by {
    avg: run_avg_order_by
    count: order_by
    max: run_max_order_by
    min: run_min_order_by
    stddev: run_stddev_order_by
    stddev_pop: run_stddev_pop_order_by
    stddev_samp: run_stddev_samp_order_by
    sum: run_sum_order_by
    var_pop: run_var_pop_order_by
    var_samp: run_var_samp_order_by
    variance: run_variance_order_by
}

"append existing jsonb value of filtered columns with new jsonb value"
input run_append_input {
    graph: jsonb
    settings: jsonb
}

"input type for inserting array relation for remote table \"run\""
input run_arr_rel_insert_input {
    data: [run_insert_input!]!
    on_conflict: run_on_conflict
}

"order by avg() on columns of table \"run\""
input run_avg_order_by {
    id: order_by
    project_id: order_by
    run_by_user: order_by
}

"Boolean expression to filter rows from the table \"run\". All fields are combined with a logical 'AND'."
input run_bool_exp {
    _and: [run_bool_exp]
    _not: run_bool_exp
    _or: [run_bool_exp]
    finished_at: timestamptz_comparison_exp
    graph: jsonb_comparison_exp
    id: bigint_comparison_exp
    paths: run_path_bool_exp
    project: project_bool_exp
    project_id: Int_comparison_exp
    run_by_user: Int_comparison_exp
    settings: jsonb_comparison_exp
    started_at: timestamptz_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input run_delete_at_path_input {
    graph: [String]
    settings: [String]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input run_delete_elem_input {
    graph: Int
    settings: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input run_delete_key_input {
    graph: String
    settings: String
}

"input type for incrementing integer column in table \"run\""
input run_inc_input {
    id: bigint
    project_id: Int
    run_by_user: Int
}

"input type for inserting data into table \"run\""
input run_insert_input {
    finished_at: timestamptz
    graph: jsonb
    id: bigint
    paths: run_path_arr_rel_insert_input
    project: project_obj_rel_insert_input
    project_id: Int
    run_by_user: Int
    settings: jsonb
    started_at: timestamptz
}

"order by max() on columns of table \"run\""
input run_max_order_by {
    finished_at: order_by
    id: order_by
    project_id: order_by
    run_by_user: order_by
    started_at: order_by
}

"order by min() on columns of table \"run\""
input run_min_order_by {
    finished_at: order_by
    id: order_by
    project_id: order_by
    run_by_user: order_by
    started_at: order_by
}

"input type for inserting object relation for remote table \"run\""
input run_obj_rel_insert_input {
    data: run_insert_input!
    on_conflict: run_on_conflict
}

"on conflict condition type for table \"run\""
input run_on_conflict {
    constraint: run_constraint!
    update_columns: [run_update_column!]!
    where: run_bool_exp
}

"ordering options when selecting data from \"run\""
input run_order_by {
    finished_at: order_by
    graph: order_by
    id: order_by
    paths_aggregate: run_path_aggregate_order_by
    project: project_order_by
    project_id: order_by
    run_by_user: order_by
    settings: order_by
    started_at: order_by
}

"order by aggregate values of table \"run_path\""
input run_path_aggregate_order_by {
    avg: run_path_avg_order_by
    count: order_by
    max: run_path_max_order_by
    min: run_path_min_order_by
    stddev: run_path_stddev_order_by
    stddev_pop: run_path_stddev_pop_order_by
    stddev_samp: run_path_stddev_samp_order_by
    sum: run_path_sum_order_by
    var_pop: run_path_var_pop_order_by
    var_samp: run_path_var_samp_order_by
    variance: run_path_variance_order_by
}

"append existing jsonb value of filtered columns with new jsonb value"
input run_path_append_input {
    edges: jsonb
    settings: jsonb
}

"input type for inserting array relation for remote table \"run_path\""
input run_path_arr_rel_insert_input {
    data: [run_path_insert_input!]!
    on_conflict: run_path_on_conflict
}

"order by avg() on columns of table \"run_path\""
input run_path_avg_order_by {
    id: order_by
    run_id: order_by
}

"Boolean expression to filter rows from the table \"run_path\". All fields are combined with a logical 'AND'."
input run_path_bool_exp {
    _and: [run_path_bool_exp]
    _not: run_path_bool_exp
    _or: [run_path_bool_exp]
    edges: jsonb_comparison_exp
    finished_at: timestamptz_comparison_exp
    id: bigint_comparison_exp
    run: run_bool_exp
    run_id: bigint_comparison_exp
    settings: jsonb_comparison_exp
    started_at: timestamptz_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input run_path_delete_at_path_input {
    edges: [String]
    settings: [String]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input run_path_delete_elem_input {
    edges: Int
    settings: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input run_path_delete_key_input {
    edges: String
    settings: String
}

"input type for incrementing integer column in table \"run_path\""
input run_path_inc_input {
    id: bigint
    run_id: bigint
}

"input type for inserting data into table \"run_path\""
input run_path_insert_input {
    edges: jsonb
    finished_at: timestamptz
    id: bigint
    run: run_obj_rel_insert_input
    run_id: bigint
    settings: jsonb
    started_at: timestamptz
}

"order by max() on columns of table \"run_path\""
input run_path_max_order_by {
    finished_at: order_by
    id: order_by
    run_id: order_by
    started_at: order_by
}

"order by min() on columns of table \"run_path\""
input run_path_min_order_by {
    finished_at: order_by
    id: order_by
    run_id: order_by
    started_at: order_by
}

"input type for inserting object relation for remote table \"run_path\""
input run_path_obj_rel_insert_input {
    data: run_path_insert_input!
    on_conflict: run_path_on_conflict
}

"on conflict condition type for table \"run_path\""
input run_path_on_conflict {
    constraint: run_path_constraint!
    update_columns: [run_path_update_column!]!
    where: run_path_bool_exp
}

"ordering options when selecting data from \"run_path\""
input run_path_order_by {
    edges: order_by
    finished_at: order_by
    id: order_by
    run: run_order_by
    run_id: order_by
    settings: order_by
    started_at: order_by
}

"primary key columns input for table: \"run_path\""
input run_path_pk_columns_input {
    id: bigint!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input run_path_prepend_input {
    edges: jsonb
    settings: jsonb
}

"input type for updating data in table \"run_path\""
input run_path_set_input {
    edges: jsonb
    finished_at: timestamptz
    id: bigint
    run_id: bigint
    settings: jsonb
    started_at: timestamptz
}

"order by stddev() on columns of table \"run_path\""
input run_path_stddev_order_by {
    id: order_by
    run_id: order_by
}

"order by stddev_pop() on columns of table \"run_path\""
input run_path_stddev_pop_order_by {
    id: order_by
    run_id: order_by
}

"order by stddev_samp() on columns of table \"run_path\""
input run_path_stddev_samp_order_by {
    id: order_by
    run_id: order_by
}

"order by sum() on columns of table \"run_path\""
input run_path_sum_order_by {
    id: order_by
    run_id: order_by
}

"order by var_pop() on columns of table \"run_path\""
input run_path_var_pop_order_by {
    id: order_by
    run_id: order_by
}

"order by var_samp() on columns of table \"run_path\""
input run_path_var_samp_order_by {
    id: order_by
    run_id: order_by
}

"order by variance() on columns of table \"run_path\""
input run_path_variance_order_by {
    id: order_by
    run_id: order_by
}

"primary key columns input for table: \"run\""
input run_pk_columns_input {
    id: bigint!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input run_prepend_input {
    graph: jsonb
    settings: jsonb
}

"input type for updating data in table \"run\""
input run_set_input {
    finished_at: timestamptz
    graph: jsonb
    id: bigint
    project_id: Int
    run_by_user: Int
    settings: jsonb
    started_at: timestamptz
}

"order by stddev() on columns of table \"run\""
input run_stddev_order_by {
    id: order_by
    project_id: order_by
    run_by_user: order_by
}

"order by stddev_pop() on columns of table \"run\""
input run_stddev_pop_order_by {
    id: order_by
    project_id: order_by
    run_by_user: order_by
}

"order by stddev_samp() on columns of table \"run\""
input run_stddev_samp_order_by {
    id: order_by
    project_id: order_by
    run_by_user: order_by
}

"order by sum() on columns of table \"run\""
input run_sum_order_by {
    id: order_by
    project_id: order_by
    run_by_user: order_by
}

"order by var_pop() on columns of table \"run\""
input run_var_pop_order_by {
    id: order_by
    project_id: order_by
    run_by_user: order_by
}

"order by var_samp() on columns of table \"run\""
input run_var_samp_order_by {
    id: order_by
    project_id: order_by
    run_by_user: order_by
}

"order by variance() on columns of table \"run\""
input run_variance_order_by {
    id: order_by
    project_id: order_by
    run_by_user: order_by
}

"expression to compare columns of type timestamptz. All fields are combined with logical 'AND'."
input timestamptz_comparison_exp {
    _eq: timestamptz
    _gt: timestamptz
    _gte: timestamptz
    _in: [timestamptz!]
    _is_null: Boolean
    _lt: timestamptz
    _lte: timestamptz
    _neq: timestamptz
    _nin: [timestamptz!]
}

"order by aggregate values of table \"user\""
input user_aggregate_order_by {
    avg: user_avg_order_by
    count: order_by
    max: user_max_order_by
    min: user_min_order_by
    stddev: user_stddev_order_by
    stddev_pop: user_stddev_pop_order_by
    stddev_samp: user_stddev_samp_order_by
    sum: user_sum_order_by
    var_pop: user_var_pop_order_by
    var_samp: user_var_samp_order_by
    variance: user_variance_order_by
}

"input type for inserting array relation for remote table \"user\""
input user_arr_rel_insert_input {
    data: [user_insert_input!]!
    on_conflict: user_on_conflict
}

"order by avg() on columns of table \"user\""
input user_avg_order_by {
    id: order_by
}

"Boolean expression to filter rows from the table \"user\". All fields are combined with a logical 'AND'."
input user_bool_exp {
    _and: [user_bool_exp]
    _not: user_bool_exp
    _or: [user_bool_exp]
    firebase_id: String_comparison_exp
    id: Int_comparison_exp
    name: String_comparison_exp
    owner_of_organizations: organization_bool_exp
}

"input type for incrementing integer column in table \"user\""
input user_inc_input {
    id: Int
}

"input type for inserting data into table \"user\""
input user_insert_input {
    firebase_id: String
    id: Int
    name: String
    owner_of_organizations: organization_arr_rel_insert_input
}

"order by max() on columns of table \"user\""
input user_max_order_by {
    firebase_id: order_by
    id: order_by
    name: order_by
}

"order by min() on columns of table \"user\""
input user_min_order_by {
    firebase_id: order_by
    id: order_by
    name: order_by
}

"input type for inserting object relation for remote table \"user\""
input user_obj_rel_insert_input {
    data: user_insert_input!
    on_conflict: user_on_conflict
}

"on conflict condition type for table \"user\""
input user_on_conflict {
    constraint: user_constraint!
    update_columns: [user_update_column!]!
    where: user_bool_exp
}

"ordering options when selecting data from \"user\""
input user_order_by {
    firebase_id: order_by
    id: order_by
    name: order_by
    owner_of_organizations_aggregate: organization_aggregate_order_by
}

"primary key columns input for table: \"user\""
input user_pk_columns_input {
    id: Int!
}

"input type for updating data in table \"user\""
input user_set_input {
    firebase_id: String
    id: Int
    name: String
}

"order by stddev() on columns of table \"user\""
input user_stddev_order_by {
    id: order_by
}

"order by stddev_pop() on columns of table \"user\""
input user_stddev_pop_order_by {
    id: order_by
}

"order by stddev_samp() on columns of table \"user\""
input user_stddev_samp_order_by {
    id: order_by
}

"order by sum() on columns of table \"user\""
input user_sum_order_by {
    id: order_by
}

"order by var_pop() on columns of table \"user\""
input user_var_pop_order_by {
    id: order_by
}

"order by var_samp() on columns of table \"user\""
input user_var_samp_order_by {
    id: order_by
}

"order by variance() on columns of table \"user\""
input user_variance_order_by {
    id: order_by
}

"expression to compare columns of type uuid. All fields are combined with logical 'AND'."
input uuid_comparison_exp {
    _eq: uuid
    _gt: uuid
    _gte: uuid
    _in: [uuid!]
    _is_null: Boolean
    _lt: uuid
    _lte: uuid
    _neq: uuid
    _nin: [uuid!]
}


scalar bigint

scalar jsonb

scalar timestamptz

scalar uuid